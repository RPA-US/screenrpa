{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.test import TestCase\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os \n",
    "import torch\n",
    "from SOM.UiComponent import UiComponent\n",
    "from SOM import utils\n",
    "from SOM import ip_draw \n",
    "import random\n",
    "from SOM.sam import get_sam_gui_components_crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_som(root_path, screenshots_names, image_folder_path, sam_checkpoint):\n",
    "    COMPOS_JSON_PATH = root_path+'compos_json/'\n",
    "    MASK_JSON_PATH = root_path+'mask_json/'\n",
    "    TIME_JSON_PATH = root_path+'time_json/'\n",
    "\n",
    "    for i,name in enumerate(screenshots_names):\n",
    "        name = name.split('.')[0]\n",
    "        recortes_path=root_path+'compos_npy/'+name+'.npy'\n",
    "        path_to_save_mask_npy=root_path+'mask_elements_npy/'+name\n",
    "        checkpoint_path=\"../../checkpoints/\" # Suposed to be: featureextraction/SOM/checkpoints\n",
    "        clips, uicompos, mask_json, compos_json, arrays_dict,dict_times = get_sam_gui_components_crops(param_img_root=image_folder_path, path_to_save_bordered_images=root_path, image_names=screenshots_names, img_index=i, checkpoint_path=checkpoint_path, checkpoint=sam_checkpoint)\n",
    "\n",
    "        time0 = time.time()\n",
    "        with open(COMPOS_JSON_PATH+name+'_'+sam_checkpoint+'.json','w') as f:\n",
    "            f.write(compos_json)\n",
    "\n",
    "        with open(MASK_JSON_PATH+name+'_'+sam_checkpoint+'.json','w') as f:\n",
    "            f.write(mask_json)\n",
    "\n",
    "        compos_aux = np.array(clips)\n",
    "        np.save(recortes_path,compos_aux)\n",
    "\n",
    "        # npy for each segmentation of SAM\n",
    "        path=path_to_save_mask_npy\n",
    "        for n in ['segmentation','crop_box']:\n",
    "            path_element = path+'_'+n+'_'+sam_checkpoint+'.npy'\n",
    "            aux = np.array(arrays_dict[n])\n",
    "            np.save(path_element,aux)\n",
    "        time1=time.time()\n",
    "        \n",
    "        dict_times['saving_results']=time1-time0\n",
    "\n",
    "        times_json = json.dumps(dict_times)\n",
    "        with open(TIME_JSON_PATH+name+'_'+sam_checkpoint+'.json','w') as f:\n",
    "            f.write(times_json)\n",
    "\n",
    "        print('There are {} components'.format(len(uicompos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../resources/gaze/gaze4/ip\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_16520\\413371598.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  compos_aux = np.array(clips)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 107 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 112 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 64 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 79 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 91 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 85 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 111 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 104 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 110 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 64 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 70 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 85 components\n",
      "../../resources/gaze/gaze4/ip\n",
      "True\n",
      "There are 71 components\n"
     ]
    }
   ],
   "source": [
    "screenshots_names = [\n",
    "    \"screenshot0012.JPEG\",\n",
    "    \"screenshot0014.JPEG\",\n",
    "    \"screenshot0015.JPEG\",\n",
    "    \"screenshot0016.JPEG\",\n",
    "    \"screenshot0017.JPEG\",\n",
    "    \"screenshot0018.JPEG\",\n",
    "    \"screenshot0019.JPEG\",\n",
    "    \"screenshot0020.JPEG\",\n",
    "    \"screenshot0022.JPEG\",\n",
    "    \"screenshot0023.JPEG\",\n",
    "    \"screenshot0024.JPEG\",\n",
    "    \"screenshot0025.JPEG\",\n",
    "    \"screenshot0026.JPEG\"\n",
    "]\n",
    "\n",
    "root = \"../../../resources/gaze/gaze4/\"\n",
    "obtain_som(root, screenshots_names, root, \"l\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "root_path = \"/screenrpa/resources/metadata/\"\n",
    "\n",
    "json_filenames = [\"221-metainfo.json\", \"222-metainfo.json\"]  \n",
    "\n",
    "json_files = [root_path + filename for filename in json_filenames]\n",
    "\n",
    "for i, json_path in enumerate(json_files):\n",
    "    json_file = json.load(open(json_path))\n",
    "\n",
    "    for key in json_file:\n",
    "        subjson = json_file[key][\"ui_elements_detection\"][\"screenshots\"]\n",
    "        \n",
    "        columns_names = [\n",
    "            \"detect_images_components duration\",\n",
    "            \"detect_images_components #UICompos\",\n",
    "            \"detect_images_components get_binary_map_time\",\n",
    "            \"detect_images_components get_component_detection\",\n",
    "            \"detect_images_components merge_intersected_compos\",\n",
    "            \"detect_images_components compo_block_recognition\",\n",
    "            \"detect_images_components nesting_inspection\",\n",
    "            \"detect_images_components save_detection_result\",\n",
    "            \"detect_images_components compo_clipping\"\n",
    "            ]\n",
    "\n",
    "        df = pd.DataFrame([], columns=[\"screenshot\"] + columns_names)\n",
    "\n",
    "        for j, screen_key in enumerate(subjson):\n",
    "            row = [screen_key]\n",
    "            for column_name in columns_names:\n",
    "                row += [subjson[screen_key][column_name]]\n",
    "            df.loc[j] = row\n",
    "            \n",
    "        df.to_csv(root_path + json_filenames[i] + \"_metrics.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
