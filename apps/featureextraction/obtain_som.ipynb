{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.test import TestCase\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os \n",
    "import torch\n",
    "from SOM.UiComponent import UiComponent\n",
    "from SOM import utils\n",
    "from SOM import ip_draw \n",
    "import random\n",
    "from SOM.sam import get_sam_gui_components_crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_som(root_path, screenshots_names, image_folder_path, TIME_JSON_PATH, sam_checkpoint):\n",
    "    COMPOS_JSON_PATH = 'compos_json/'\n",
    "    MASK_JSON_PATH = 'mask_json/'\n",
    "\n",
    "    for i,name in enumerate(screenshots_names):\n",
    "        name = name.split('.')[0]\n",
    "        recortes_path=root_path+'compos_npy/'+name+'.npy'\n",
    "        path_to_save_mask_npy=root_path+'mask_elements_npy/'+name\n",
    "        \n",
    "        clips, uicompos, mask_json, compos_json, arrays_dict,dict_times = get_sam_gui_components_crops(param_img_root=image_folder_path, path_to_save_bordered_images=root_path, image_names=screenshots_names, img_index=i, checkpoint=sam_checkpoint)\n",
    "\n",
    "        time0 = time.time()\n",
    "        with open(COMPOS_JSON_PATH+name+'_'+sam_checkpoint+'.json','w') as f:\n",
    "            f.write(compos_json)\n",
    "\n",
    "        with open(MASK_JSON_PATH+name+'_'+sam_checkpoint+'.json','w') as f:\n",
    "            f.write(mask_json)\n",
    "\n",
    "        compos_aux = np.array(clips)\n",
    "        np.save(recortes_path,compos_aux)\n",
    "\n",
    "        # npy for each segmentation of SAM\n",
    "        path=path_to_save_mask_npy\n",
    "        for n in ['segmentation','crop_box']:\n",
    "            path_element = path+'_'+n+'_'+sam_checkpoint+'.npy'\n",
    "            aux = np.array(arrays_dict[n])\n",
    "            np.save(path_element,aux)\n",
    "        time1=time.time()\n",
    "        \n",
    "        dict_times['saving_results']=time1-time0\n",
    "\n",
    "        times_json = json.dumps(dict_times)\n",
    "        with open(TIME_JSON_PATH+name+'_'+sam_checkpoint+'.json','w') as f:\n",
    "            f.write(times_json)\n",
    "\n",
    "        print('There are {} components'.format(len(uicompos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/rim/apps/featureextraction/SOM/checkpoints/sam_vit_l_0b3195.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m screenshots_names \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mscreenshot0012.JPEG\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mscreenshot0014.JPEG\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mscreenshot0026.JPEG\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m ]\n\u001b[1;32m     16\u001b[0m root \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../../resources/gaze/gaze4/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m obtain_som(root, screenshots_names, root, root, \u001b[39m\"\u001b[39;49m\u001b[39ml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m, in \u001b[0;36mobtain_som\u001b[0;34m(root_path, screenshots_names, image_folder_path, TIME_JSON_PATH, sam_checkpoint)\u001b[0m\n\u001b[1;32m      7\u001b[0m recortes_path\u001b[39m=\u001b[39mroot_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcompos_npy/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mname\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      8\u001b[0m path_to_save_mask_npy\u001b[39m=\u001b[39mroot_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmask_elements_npy/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mname\n\u001b[0;32m---> 10\u001b[0m clips, uicompos, mask_json, compos_json, arrays_dict,dict_times \u001b[39m=\u001b[39m get_sam_gui_components_crops(param_img_root\u001b[39m=\u001b[39;49mimage_folder_path, path_to_save_bordered_images\u001b[39m=\u001b[39;49mroot_path, image_names\u001b[39m=\u001b[39;49mscreenshots_names, img_index\u001b[39m=\u001b[39;49mi, checkpoint\u001b[39m=\u001b[39;49msam_checkpoint)\n\u001b[1;32m     12\u001b[0m time0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(COMPOS_JSON_PATH\u001b[39m+\u001b[39mname\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39msam_checkpoint\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/screenrpa/apps/featureextraction/SOM/sam.py:135\u001b[0m, in \u001b[0;36mget_sam_gui_components_crops\u001b[0;34m(param_img_root, image_names, path_to_save_bordered_images, img_index, checkpoint)\u001b[0m\n\u001b[1;32m    133\u001b[0m time1\u001b[39m=\u001b[39mtime\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    134\u001b[0m \u001b[39m# torch.cuda.set_per_process_memory_fraction(fraction=0.55, device=0)\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m sam \u001b[39m=\u001b[39m sam_model_registry[model_type](checkpoint\u001b[39m=\u001b[39;49mCHECKPOINT_PATH\u001b[39m+\u001b[39;49msam_checkpoint)\n\u001b[1;32m    136\u001b[0m \u001b[39m# device = \"cuda:0\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m# sam.to(device=device)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[39m### GENERATE MASK ###\u001b[39;00m\n\u001b[1;32m    140\u001b[0m mask_generator \u001b[39m=\u001b[39m SamAutomaticMaskGenerator(sam)\n",
      "File \u001b[0;32m/screenrpa/apps/featureextraction/SOM/segment_anything/build_sam.py:28\u001b[0m, in \u001b[0;36mbuild_sam_vit_l\u001b[0;34m(checkpoint)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_sam_vit_l\u001b[39m(checkpoint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 28\u001b[0m     \u001b[39mreturn\u001b[39;00m _build_sam(\n\u001b[1;32m     29\u001b[0m         encoder_embed_dim\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m         encoder_depth\u001b[39m=\u001b[39;49m\u001b[39m24\u001b[39;49m,\n\u001b[1;32m     31\u001b[0m         encoder_num_heads\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m     32\u001b[0m         encoder_global_attn_indexes\u001b[39m=\u001b[39;49m[\u001b[39m5\u001b[39;49m, \u001b[39m11\u001b[39;49m, \u001b[39m17\u001b[39;49m, \u001b[39m23\u001b[39;49m],\n\u001b[1;32m     33\u001b[0m         checkpoint\u001b[39m=\u001b[39;49mcheckpoint,\n\u001b[1;32m     34\u001b[0m     )\n",
      "File \u001b[0;32m/screenrpa/apps/featureextraction/SOM/segment_anything/build_sam.py:104\u001b[0m, in \u001b[0;36m_build_sam\u001b[0;34m(encoder_embed_dim, encoder_depth, encoder_num_heads, encoder_global_attn_indexes, checkpoint)\u001b[0m\n\u001b[1;32m    102\u001b[0m sam\u001b[39m.\u001b[39meval()\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m checkpoint \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(checkpoint, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    105\u001b[0m         state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    106\u001b[0m     sam\u001b[39m.\u001b[39mload_state_dict(state_dict)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/rim/apps/featureextraction/SOM/checkpoints/sam_vit_l_0b3195.pth'"
     ]
    }
   ],
   "source": [
    "screenshots_names = [\n",
    "    \"screenshot0012.JPEG\",\n",
    "    \"screenshot0014.JPEG\",\n",
    "    \"screenshot0015.JPEG\",\n",
    "    \"screenshot0016.JPEG\",\n",
    "    \"screenshot0017.JPEG\",\n",
    "    \"screenshot0018.JPEG\",\n",
    "    \"screenshot0019.JPEG\",\n",
    "    \"screenshot0020.JPEG\",\n",
    "    \"screenshot0022.JPEG\",\n",
    "    \"screenshot0023.JPEG\",\n",
    "    \"screenshot0024.JPEG\",\n",
    "    \"screenshot0025.JPEG\",\n",
    "    \"screenshot0026.JPEG\"\n",
    "]\n",
    "root = \"../../resources/gaze/gaze4/\"\n",
    "obtain_som(root, screenshots_names, root, root, \"l\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
